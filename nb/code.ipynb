{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that loads the classifier \n",
    "def define_classifier():\n",
    "    classifier = pipeline(\"text-classification\", \n",
    "                        model=\"j-hartmann/emotion-english-distilroberta-base\", \n",
    "                        return_all_scores=True)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function loading the dataframe\n",
    "def load_data(filepath): #takes path to the data as argument \n",
    "    filename = os.path.join(filepath)\n",
    "\n",
    "    data = pd.read_csv(filename, index_col=0)\n",
    "    return data\n",
    "\n",
    "data = load_data(\"../data/fake_or_real_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903</th>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>DOJ COMPLAINT: Comey Under Fire Over Partisan ...</td>\n",
       "      <td>DOJ COMPLAINT: Comey Under Fire Over Partisan ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9337</th>\n",
       "      <td>Radio Derb Is On The Air–Leonardo And Brazil’s...</td>\n",
       "      <td></td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8737</th>\n",
       "      <td>Assange claims ‘crazed’ Clinton campaign tried...</td>\n",
       "      <td>Julian Assange has claimed the Hillary Clinton...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8062</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8622</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3164 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title   \n",
       "8476                        You Can Smell Hillary’s Fear  \\\n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "6903                                         Tehran, USA   \n",
       "7341   Girl Horrified At What She Watches Boyfriend D...   \n",
       "...                                                  ...   \n",
       "6143   DOJ COMPLAINT: Comey Under Fire Over Partisan ...   \n",
       "9337   Radio Derb Is On The Air–Leonardo And Brazil’s...   \n",
       "8737   Assange claims ‘crazed’ Clinton campaign tried...   \n",
       "8062   The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "8622   Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "\n",
       "                                                    text label  \n",
       "8476   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "6903     \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "7341   Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "...                                                  ...   ...  \n",
       "6143   DOJ COMPLAINT: Comey Under Fire Over Partisan ...  FAKE  \n",
       "9337                                                      FAKE  \n",
       "8737   Julian Assange has claimed the Hillary Clinton...  FAKE  \n",
       "8062   The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "8622    Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "\n",
       "[3164 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_fake_barplot():\n",
    "    data = load_data(\"../data/fake_or_real_news.csv\")\n",
    "    df_fake = data[data['label'] == 'FAKE']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/home/coder/.local/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifier = define_classifier() #calling classifier function and saving it into variable 'classifier'\n",
    "\n",
    "#Perform emotion classification and saving as a pandas dataframe\n",
    "def emotion_classification():  \n",
    "    titles = data[\"title\"]\n",
    "\n",
    "    anger = []\n",
    "    disgust = []\n",
    "    fear = []\n",
    "    joy = []\n",
    "    neutral = []\n",
    "    sadness = []\n",
    "    surprise = []\n",
    "\n",
    "    for title in titles:\n",
    "        score = classifier(title)\n",
    "        for scores in score:\n",
    "            anger.append(scores[0][\"score\"])\n",
    "            disgust.append(scores[1][\"score\"])\n",
    "            fear.append(scores[2][\"score\"])\n",
    "            joy.append(scores[3][\"score\"])\n",
    "            neutral.append(scores[4][\"score\"])\n",
    "            sadness.append(scores[5][\"score\"])\n",
    "            surprise.append(scores[6][\"score\"])\n",
    "    \n",
    "    return titles, anger, disgust, fear, joy, neutral, sadness, surprise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     data_filepath \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../out/data.csv\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# name your output file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     df\u001b[39m.\u001b[39mto_csv(data_filepath)\n\u001b[0;32m----> 8\u001b[0m save_emotion_df()\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36msave_emotion_df\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_emotion_df\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     titles, anger, disgust, fear, joy, neutral, sadness, surprise \u001b[39m=\u001b[39m emotion_classification()\n\u001b[1;32m      3\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(titles, anger, disgust, fear, joy, neutral, sadness, surprise)), columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mheadline\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39manger\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdisgust\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mjoy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneutral\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msadness\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msurprise\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m     data_filepath \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../out/data.csv\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# name your output file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36memotion_classification\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m surprise \u001b[39m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m title \u001b[39min\u001b[39;00m titles:\n\u001b[0;32m---> 16\u001b[0m     score \u001b[39m=\u001b[39m classifier(title)\n\u001b[1;32m     17\u001b[0m     \u001b[39mfor\u001b[39;00m scores \u001b[39min\u001b[39;00m score:\n\u001b[1;32m     18\u001b[0m         anger\u001b[39m.\u001b[39mappend(scores[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:155\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    156\u001b[0m     \u001b[39m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     _legacy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtop_k\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/base.py:1109\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1102\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1103\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         )\n\u001b[1;32m   1107\u001b[0m     )\n\u001b[1;32m   1108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/base.py:1116\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1115\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1116\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1117\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/base.py:1010\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1009\u001b[0m     model_inputs[\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1010\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1011\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1012\u001b[0m     inference_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_inference_context()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:182\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward\u001b[39m(\u001b[39mself\u001b[39m, model_inputs):\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/training.py:558\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    556\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 558\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1142\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1144\u001b[0m ):\n\u001b[0;32m-> 1145\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:433\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    432\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 433\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49munpacked_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:1359\u001b[0m, in \u001b[0;36mTFRobertaForSequenceClassification.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[1;32m   1330\u001b[0m \u001b[39m@unpack_inputs\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[39m@add_start_docstrings_to_model_forward\u001b[39m(ROBERTA_INPUTS_DOCSTRING\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mbatch_size, sequence_length\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1332\u001b[0m \u001b[39m@add_code_sample_docstrings\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     training: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1352\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[TFSequenceClassifierOutput, Tuple[tf\u001b[39m.\u001b[39mTensor]]:\n\u001b[1;32m   1353\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[39m    labels (`tf.Tensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[39m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m \u001b[39m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m \u001b[39m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1358\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1359\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[1;32m   1360\u001b[0m         input_ids,\n\u001b[1;32m   1361\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1362\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1363\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1364\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1365\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1366\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1367\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1368\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1369\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1370\u001b[0m     )\n\u001b[1;32m   1371\u001b[0m     sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1372\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output, training\u001b[39m=\u001b[39mtraining)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1142\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1144\u001b[0m ):\n\u001b[0;32m-> 1145\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:433\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    432\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 433\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49munpacked_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:744\u001b[0m, in \u001b[0;36mTFRobertaMainLayer.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m     head_mask \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers\n\u001b[0;32m--> 744\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    745\u001b[0m     hidden_states\u001b[39m=\u001b[39;49membedding_output,\n\u001b[1;32m    746\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    747\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    748\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    749\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    750\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    751\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    752\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    753\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    754\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    755\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    756\u001b[0m )\n\u001b[1;32m    758\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    759\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(hidden_states\u001b[39m=\u001b[39msequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1142\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1144\u001b[0m ):\n\u001b[0;32m-> 1145\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:542\u001b[0m, in \u001b[0;36mTFRobertaEncoder.call\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    538\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[1;32m    540\u001b[0m past_key_value \u001b[39m=\u001b[39m past_key_values[i] \u001b[39mif\u001b[39;00m past_key_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    543\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    544\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    545\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    546\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    547\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    548\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    549\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    550\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    552\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    554\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1142\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1144\u001b[0m ):\n\u001b[0;32m-> 1145\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:451\u001b[0m, in \u001b[0;36mTFRobertaLayer.call\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\n\u001b[1;32m    439\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    440\u001b[0m     hidden_states: tf\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[tf\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    449\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    452\u001b[0m         input_tensor\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    453\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    454\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    455\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    456\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    457\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    458\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    459\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    461\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    463\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1142\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1144\u001b[0m ):\n\u001b[0;32m-> 1145\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:364\u001b[0m, in \u001b[0;36mTFRobertaAttention.call\u001b[0;34m(self, input_tensor, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\n\u001b[1;32m    354\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    355\u001b[0m     input_tensor: tf\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m     training: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    363\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[tf\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 364\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attention(\n\u001b[1;32m    365\u001b[0m         hidden_states\u001b[39m=\u001b[39;49minput_tensor,\n\u001b[1;32m    366\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    367\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    368\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    369\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    370\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    371\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    372\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    374\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense_output(\n\u001b[1;32m    375\u001b[0m         hidden_states\u001b[39m=\u001b[39mself_outputs[\u001b[39m0\u001b[39m], input_tensor\u001b[39m=\u001b[39minput_tensor, training\u001b[39m=\u001b[39mtraining\n\u001b[1;32m    376\u001b[0m     )\n\u001b[1;32m    377\u001b[0m     \u001b[39m# add attentions (possibly with past_key_value) if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1142\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1144\u001b[0m ):\n\u001b[0;32m-> 1145\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:276\u001b[0m, in \u001b[0;36mTFRobertaSelfAttention.call\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey(inputs\u001b[39m=\u001b[39mhidden_states), batch_size)\n\u001b[0;32m--> 276\u001b[0m     value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue(inputs\u001b[39m=\u001b[39;49mhidden_states), batch_size)\n\u001b[1;32m    278\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(mixed_query_layer, batch_size)\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder:\n\u001b[1;32m    281\u001b[0m     \u001b[39m# if cross_attention save Tuple(tf.Tensor, tf.Tensor) of all cross attention key/value_states.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[39m# Further calls to cross_attention layer can then reuse all cross-attention\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1142\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1144\u001b[0m ):\n\u001b[0;32m-> 1145\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/layers/core/dense.py:244\u001b[0m, in \u001b[0;36mDense.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    241\u001b[0m         outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmatmul(a\u001b[39m=\u001b[39minputs, b\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel)\n\u001b[1;32m    242\u001b[0m \u001b[39m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 244\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mtensordot(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel, [[rank \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m], [\u001b[39m0\u001b[39;49m]])\n\u001b[1;32m    245\u001b[0m     \u001b[39m# Reshape the output back to the original ndim of the input.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:5166\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   5164\u001b[0m     \u001b[39mreturn\u001b[39;00m ab_matmul\n\u001b[1;32m   5165\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 5166\u001b[0m     \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39;49mreshape(\n\u001b[1;32m   5167\u001b[0m         ab_matmul, a_free_dims \u001b[39m+\u001b[39;49m b_free_dims, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   5168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5169\u001b[0m   a_free_dims \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(a_free_dims, dtype\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mint32)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:196\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmanip.reshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     61\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(tensor, shape, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m  \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mreshape(tensor, shape, name)\n\u001b[1;32m    197\u001b[0m   tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[1;32m    198\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:8570\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8568\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   8569\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 8570\u001b[0m   \u001b[39mreturn\u001b[39;00m reshape_eager_fallback(\n\u001b[1;32m   8571\u001b[0m       tensor, shape, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[1;32m   8572\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[1;32m   8573\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:8591\u001b[0m, in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8590\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape_eager_fallback\u001b[39m(tensor, shape, name, ctx):\n\u001b[0;32m-> 8591\u001b[0m   _attr_T, (tensor,) \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49margs_to_matching_eager([tensor], ctx, [])\n\u001b[1;32m   8592\u001b[0m   _attr_Tshape, (shape,) \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39margs_to_matching_eager([shape], ctx, [_dtypes\u001b[39m.\u001b[39mint32, _dtypes\u001b[39m.\u001b[39mint64, ], _dtypes\u001b[39m.\u001b[39mint32)\n\u001b[1;32m   8593\u001b[0m   _inputs_flat \u001b[39m=\u001b[39m [tensor, shape]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:227\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39margs_to_matching_eager\u001b[39m(l, ctx, allowed_dtypes, default_dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    226\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Convert sequence `l` to eager same-type Tensors.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m   \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m l) \u001b[39mand\u001b[39;00m (default_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    228\u001b[0m     \u001b[39mreturn\u001b[39;00m default_dtype, []  \u001b[39m# List is empty; assume default dtype.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m   EagerTensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mEagerTensor  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def save_emotion_df():\n",
    "    titles, anger, disgust, fear, joy, neutral, sadness, surprise = emotion_classification()\n",
    "    df = pd.DataFrame(list(zip(titles, anger, disgust, fear, joy, neutral, sadness, surprise)), columns=['headline', 'anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise'])\n",
    "    \n",
    "    data_filepath = \"../out/data.csv\"  # name your output file\n",
    "    df.to_csv(data_filepath)\n",
    "\n",
    "save_emotion_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for finding average number of a list \n",
    "def average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "plt.style.use('_mpl-gallery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x axis\n",
    "def find_average():\n",
    "    titles, anger, disgust, fear, joy, neutral, sadness, surprise = emotion_classification()\n",
    "    x = (\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\")\n",
    "    #finding the average of each emotion via average() function \n",
    "    avr_anger = average(anger)\n",
    "    avr_disgust = average(disgust)\n",
    "    avr_fear = average(fear)\n",
    "    avr_joy = average(joy)\n",
    "    avr_neutral = average(neutral)\n",
    "    avr_sadness = average(sadness)\n",
    "    avr_surprise = average(surprise)\n",
    "\n",
    "    return avr_anger, avr_disgust, avr_fear, avr_joy, avr_neutral, avr_sadness, avr_surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_barplot():\n",
    "    avr_anger, avr_disgust, avr_fear, avr_joy, avr_neutral, avr_sadness, avr_surprise = find_average()\n",
    "    #saving average values in y variable\n",
    "    y = avr_anger, avr_disgust, avr_fear, avr_joy, avr_neutral, avr_sadness, avr_surprise\n",
    "    x = ('anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise')\n",
    "\n",
    "    #create plot\n",
    "    #fig, ax = plt.subplots()\n",
    "    #plt.barh(x, y, edgecolor=\"white\", linewidth=0.7, align='center')\n",
    "    #plt.title('Average score of each emotion (all headlines)')\n",
    "    # make an agg figure\n",
    "    #fig.canvas.draw()\n",
    "    plt.barh(x, y)\n",
    "\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Average')\n",
    "    plt.title('Average emotion for all headlines')\n",
    "\n",
    "    plt.subplots_adjust(left=0.40, bottom=0.40)\n",
    "    #saving plot\n",
    "    plt.savefig('../out/average2.png')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "create_barplot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
